{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wheelchair detection training \n",
    "\n",
    "In this project, I present a Faster RCNN-based wheelchair detection system. This code performs the training and mAP accuracy measurements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named cv2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7330f40a30a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# modules from faster rcnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfrcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfrcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_helpers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroi_helpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/inavarro/Desktop/Workspace/ml/TensorFlow/keras-frcnn/frcnn/data_generators.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named cv2"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "# modules from faster rcnn \n",
    "from frcnn import config, data_generators\n",
    "from frcnn import losses as losses\n",
    "import frcnn.roi_helpers as roi_helpers\n",
    "\n",
    "# modules from keras \n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam #, SGD, RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.utils import generic_utils, plot_model \n",
    "\n",
    "# other modules \n",
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import average_precision_score\n",
    "%matplotlib.inline\n",
    "\n",
    "sys.setrecursionlimit(40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv parser accepts data from a text file in the following format:\n",
    "# filename, x1, y1, x2, y2, wheelchair\n",
    "parser =  'csv' \n",
    "\n",
    "# specidying the training path where the csv file is\n",
    "# train_path = 'csv/05_wheelchair_dataset_example.csv'\n",
    "# train_path = 'csv/05_wheelchair_dataset.csv'\n",
    "train_path = 'csv/06_wheelchair_reduced_brix.csv'\n",
    "\n",
    "# number of epochs and rois to process at once\n",
    "num_epoch = 100\n",
    "num_rois = 10\n",
    "\n",
    "# specify the input weigth path where the pre-trained model is\n",
    "# input_weight_path = 'resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "input_weight_path = 'vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "# input_weight_path = 'vgg_nda_nm_test150.h5'\n",
    "\n",
    "# specify the name of the output model to save the fine-tuned weights\n",
    "output_weight_path = 'vgg_nda_nm_test.h5'\n",
    "# options.output_weight_path = 'resnet_nda_nm_test150.h5'\n",
    "\n",
    "# specify the newtork to use, currently only vgg and resnet are supported\n",
    "# network = 'resnet50'\n",
    "network = 'vgg'\n",
    "\n",
    "# verify that arguments were specified correctly. \n",
    "if not train_path: raise Error('Error: path to training data must be specified.')\n",
    "\n",
    "# parsing data depending on the parser specified.\n",
    "if parser == 'pascal_voc': from keras_frcnn.pascal_voc_parser import get_data\n",
    "elif parser == 'simple': from keras_frcnn.simple_parser import get_data\n",
    "else: raise ValueError(\"Parser must be: 'pascal_voc' or 'simple'\")\n",
    "    \n",
    "# data augmentation \n",
    "horizontal_flips = False\n",
    "vertical_flips = False\n",
    "rot_90 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modify the condiguration object, otherwise default values will be used\n",
    "C = config.Config()\n",
    "C.use_horizontal_flips = horizontal_flips\n",
    "C.use_vertical_flips = vertical_flips\n",
    "C.rot_90 = rot_90\n",
    "C.model_path = output_weight_path\n",
    "C.num_rois = num_rois\n",
    "\n",
    "# import specified network \n",
    "if options.network == 'vgg':\n",
    "    C.network = 'vgg'\n",
    "    from keras_frcnn import vgg as nn\n",
    "elif options.network == 'resnet50':\n",
    "    from keras_frcnn import resnet as nn\n",
    "    C.network = 'resnet50'\n",
    "else:\n",
    "    print('Not a valid model')\n",
    "    raise ValueError\n",
    "\n",
    "# pre-trained weights\n",
    "C.base_net_weights = input_weight_path\n",
    "\n",
    "all_imgs, classes_count, class_mapping = get_data(options.train_path)\n",
    "\n",
    "# check if there is background class specified in the parsed data\n",
    "if 'bg' not in classes_count:\n",
    "    classes_count['bg'] = 0\n",
    "    class_mapping['bg'] = len(class_mapping)\n",
    "\n",
    "C.class_mapping = class_mapping\n",
    "\n",
    "print('Training images per class:')\n",
    "pprint.pprint(classes_count)\n",
    "print('Num classes (including bg) = {}'.format(len(classes_count)))\n",
    "\n",
    "config_output_filename = config_filename\n",
    "\n",
    "with open(config_output_filename, 'wb') as config_f:\n",
    "    pickle.dump(C,config_f)\n",
    "    print('Config has been written to {}, and can be loaded when testing to ensure correct results'\n",
    "          .format(config_output_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "Need to fix this part. Pickle does not work on generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set it to true if starting from a checkpoint \n",
    "checkpoint = False\n",
    "\n",
    "if not checkpoint:\n",
    "    \n",
    "    # divide dataset into train and test\n",
    "    random.shuffle(all_imgs)\n",
    "    num_imgs = len(all_imgs)\n",
    "    \n",
    "    train_imgs = [s for s in all_imgs if s['imageset'] == 'trainval']\n",
    "    val_imgs = [s for s in all_imgs if s['imageset'] == 'test']\n",
    "    \n",
    "    print('Num train samples {}'.format(len(train_imgs)))\n",
    "    print('Num val samples {}'.format(len(val_imgs)))\n",
    "    \n",
    "    # create data generator for train set\n",
    "    data_gen_train = data_generators.get_anchor_gt(all_imgs, classes_count, C, \n",
    "                                                   nn.get_img_output_length, \n",
    "                                                   K.image_dim_ordering(), \n",
    "                                                   mode='train')\n",
    "    # create data generator for test set\n",
    "    data_gen_val = data_generators.get_anchor_gt(val_imgs, classes_count, C, \n",
    "                                                nn.get_img_output_length, \n",
    "                                                K.image_dim_ordering(), \n",
    "                                                mode='test')\n",
    "    \n",
    "    # save train and test sets if needed later \n",
    "    with open(\"train.pickle\", \"wb\") as f: \n",
    "        pickle.dump(data_gen_train, f)\n",
    "        print(\"Saved train generator into {} file\".format(f))\n",
    "    \n",
    "    with open(\"val.pickle\", \"wb\") as f: \n",
    "        pickle.dump(data_gen_val, f)\n",
    "        print(\"Saved train generator into {] file\".format(f))\n",
    "    \n",
    "else:\n",
    "    # load sets\n",
    "    data_gen_trainl = pickle.load(open(\"train.pickle\", \"rb\"))\n",
    "    data_gen_val = pickle.load(open(\"val.pickle\", \"rb\"))\n",
    "    print(\"Loaded data generators from pickle files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models \n",
    "\n",
    "Defining parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image settings\n",
    "input_shape_img = (None, None, 3)\n",
    "img_input = Input(shape=input_shape_img)\n",
    "roi_input = Input(shape=(None, 4))\n",
    "\n",
    "# define the RPN, built on the base layers\n",
    "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
    "\n",
    "# define the base network (resnet here, can be VGG, Inception, etc)\n",
    "shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "# define optimizers \n",
    "optimizer = Adam(lr=1e-5)\n",
    "optimizer_classifier = Adam(lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RPN model returns proposed class, regrs and base layers \n",
    "rpn = nn.rpn(shared_layers, num_anchors)\n",
    "\n",
    "model_rpn = Model(img_input, rpn[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifier model returns predicted class and regresor\n",
    "classifier = nn.classifier(shared_layers, roi_input, C.num_rois, \n",
    "                           nb_classes=len(classes_count), trainable=True)  \n",
    "\n",
    "model_classifier = Model([img_input, roi_input], classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this model holds both RPN and classifier used to load/save model weights\n",
    "model_all = Model([img_input, roi_input], rpn[:2] + classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model weights\n",
    "try:\n",
    "    print('loading weights from {}'.format(C.base_net_weights))\n",
    "    model_rpn.load_weights(C.base_net_weights, by_name=True)\n",
    "    model_classifier.load_weights(C.base_net_weights, by_name=True)\n",
    "except:\n",
    "    print('Could not load pretrained model weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile rpn \n",
    "model_rpn.compile(optimizer=optimizer, \n",
    "                  loss=[losses.rpn_loss_cls(num_anchors), \n",
    "                        losses.rpn_loss_regr(num_anchors)])\n",
    "# compile class\n",
    "model_classifier.compile(optimizer=optimizer_classifier, \n",
    "                         loss=[losses.class_loss_cls, \n",
    "                               losses.class_loss_regr(len(classes_count)-1)],   ## change this \n",
    "                         metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
    "\n",
    "# compile merged models \n",
    "model_all.compile(optimizer='sgd', loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training \n",
    "\n",
    "Set parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters \n",
    "epoch_length = 1000                   # change to 1000 when not debugging\n",
    "num_epochs = num_epoch\n",
    "epoch_change = 1.0 /  epoch_length \n",
    "vis = True\n",
    "iter_num = 0\n",
    "start_time = time.time()\n",
    "class_mapping_inv = {v: k for k, v in class_mapping.items()}\n",
    "rpn_accuracy_rpn_monitor = []\n",
    "rpn_accuracy_for_epoch = []\n",
    "losses = np.zeros((epoch_length, 5))\n",
    "best_loss = np.Inf\n",
    "plot_acc_loss = { 'epoch': [],           'rpn_acc': [], \n",
    "                  'cls_acc': [],         'loss_rpn_cls': [],   \n",
    "                  'loss_rpn_regr': [],   'loss_class_cls': [], \n",
    "                  'loss_class_regr': [], 'epoch_num': [], \n",
    "                  'total_loss':[],       'precision': [], \n",
    "                  'recall':[],           'mAP' : []}                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Starting training')\n",
    "\n",
    "for epoch_num in range(num_epochs):\n",
    "    \n",
    "    cont = raw_input(\"Continue traninig? [1/0]:\")\n",
    "    if int(cont): pass\n",
    "    else: break\n",
    "    \n",
    "    progbar = generic_utils.Progbar(epoch_length)\n",
    "    print('Epoch: {}/{}'.format(epoch_num + 1, num_epochs))\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # end of epoch, calculate av. overlapping bboxes           \n",
    "            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
    "                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
    "                rpn_accuracy_rpn_monitor = []               \n",
    "                print('Av. num. of overlapping bboxes from RPN = {} for {} previous iterations'\n",
    "                      .format(mean_overlapping_bboxes, epoch_length))\n",
    "                if mean_overlapping_bboxes == 0:\n",
    "                    print('RPN is not producing bboxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
    "            \n",
    "            # get next data generator \n",
    "            X, Y, img_data = next(data_gen_train)\n",
    "          \n",
    "            # calculate rpn loss             \n",
    "            loss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "\n",
    "            # predict on batch             \n",
    "            P_rpn = model_rpn.predict_on_batch(X)\n",
    "\n",
    "            # convert rpn to region of interest             \n",
    "            R = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], C,K.image_dim_ordering(), \n",
    "                                       use_regr=True, overlap_thresh=0.7, \n",
    "                                       max_boxes=300)\n",
    "\n",
    "            # calculate IoUs - function converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
    "            X2, Y1, Y2, IouS = roi_helpers.calc_iou(R, img_data, C, class_mapping)\n",
    "\n",
    "            if X2 is None:\n",
    "                rpn_accuracy_rpn_monitor.append(0)\n",
    "                rpn_accuracy_for_epoch.append(0)\n",
    "                continue\n",
    "\n",
    "            neg_samples = np.where(Y1[0, :, -1] == 1)\n",
    "            pos_samples = np.where(Y1[0, :, -1] == 0)\n",
    "            \n",
    "            if len(neg_samples) > 0: neg_samples = neg_samples[0]\n",
    "            else: neg_samples = []\n",
    "\n",
    "            if len(pos_samples) > 0: pos_samples = pos_samples[0]\n",
    "            else: pos_samples = []\n",
    "            \n",
    "            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
    "            rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
    "\n",
    "            if C.num_rois > 1:\n",
    "                if len(pos_samples) < C.num_rois//2:\n",
    "                    selected_pos_samples = pos_samples.tolist()\n",
    "                else:\n",
    "                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
    "                \n",
    "                try:\n",
    "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
    "                except:\n",
    "                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
    "\n",
    "                sel_samples = selected_pos_samples + selected_neg_samples\n",
    "            else:\n",
    "                # if num_rois = 1, we pick a random pos or neg sample\n",
    "                selected_pos_samples = pos_samples.tolist()\n",
    "                selected_neg_samples = neg_samples.tolist()\n",
    "                if np.random.randint(0, 2): sel_samples = random.choice(neg_samples)\n",
    "                else: sel_samples = random.choice(pos_samples)\n",
    "            \n",
    "            # calculate losses\n",
    "            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], \n",
    "                                                         [Y1[:, sel_samples, :], \n",
    "                                                          Y2[:, sel_samples, :]])\n",
    "            losses[iter_num, 0] = loss_rpn[1]\n",
    "            losses[iter_num, 1] = loss_rpn[2]\n",
    "            losses[iter_num, 2] = loss_class[1]\n",
    "            losses[iter_num, 3] = loss_class[2]\n",
    "            losses[iter_num, 4] = loss_class[3]\n",
    "            \n",
    "            # check if there are metrics \n",
    "            # print(\"model metrics rpn \\n {} : \".format(model_rpn.metrics))\n",
    "            # print(\"model metrics classifier \\n {} : \".format(model_classifier.metrics))\n",
    "            # print(\"model metrics all \\n {} : \".format(model_all.metrics))\n",
    "            \n",
    "            # update progrbar with current losses, slows down the process\n",
    "            progbar.update(iter_num, [('rpn_cls', loss_rpn[1]), ('rpn_regr', loss_rpn[2]),\n",
    "                                      ('det_cls', loss_class[1]), ('det_regr', loss_class[2])])\n",
    "            \n",
    "            # Values to plot\n",
    "            plot_acc_loss['epoch'].append(epoch_change)\n",
    "            plot_acc_loss['rpn_acc'].append(len(pos_samples))\n",
    "            plot_acc_loss['cls_acc'].append(losses[iter_num, 4])\n",
    "            plot_acc_loss['loss_rpn_cls'].append(losses[iter_num, 0])\n",
    "            plot_acc_loss['loss_rpn_regr'].append(losses[iter_num, 1])\n",
    "            plot_acc_loss['loss_class_cls'].append(losses[iter_num, 2])\n",
    "            plot_acc_loss['loss_class_regr'].append(losses[iter_num, 3])\n",
    "            epoch_change += epoch_change                 \n",
    "            \n",
    "            iter_num += 1\n",
    "            \n",
    "            if iter_num == epoch_length:\n",
    "                \n",
    "                # calculate epoch mean losses accordingly\n",
    "                loss_rpn_cls = np.mean(losses[:, 0])\n",
    "                loss_rpn_regr = np.mean(losses[:, 1])\n",
    "                loss_class_cls = np.mean(losses[:, 2])\n",
    "                loss_class_regr = np.mean(losses[:, 3])\n",
    "                \n",
    "                # calculate mean accuracy\n",
    "                class_acc = np.mean(losses[:, 4])\n",
    "                \n",
    "                # Plot rpn losses figure \n",
    "                fig_loss = plt.figure(0)\n",
    "                plt.plot(losses[:, 0], 'r', label='l-rpn cls')  \n",
    "                plt.plot(losses[:, 1], 'b', label='l-rpn regr')\n",
    "                plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "                           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "                plt.title('rpn loss during epoch {}'.format(epoch_num + 1), y=1.1)\n",
    "                plt.ylabel('loss')\n",
    "                plt.xlabel('epoch length')\n",
    "                plt.ylim(0, 8)\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                fig_loss.savefig('results/loss_rpn_epoch_{}.pdf'.format(epoch_num + 1))\n",
    "                \n",
    "                # plot class losses \n",
    "                fig_loss = plt.figure(0)\n",
    "                plt.plot(losses[:, 2], 'g', label='l-class cls')\n",
    "                plt.plot(losses[:, 3], 'm', label='l-class regr')\n",
    "                plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "                           ncol=4, mode=\"expand\", borderaxespad=0.)\n",
    "                plt.title('cls loss during epoch {}'.format(epoch_num + 1), y=1.1)\n",
    "                plt.ylabel('loss')\n",
    "                plt.xlabel('epoch length')\n",
    "                plt.ylim(0, 8)\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                fig_loss.savefig('results/loss_class_epoch_{}.pdf'.format(epoch_num + 1))\n",
    "                \n",
    "                # plot accuracy figure \n",
    "                fig_acc = plt.figure(0)\n",
    "                plt.plot(losses[:, 4], 'c', label='accuracy')\n",
    "                plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "                           ncol=4, mode=\"expand\", borderaxespad=0.)\n",
    "                plt.title('classifier accuracy for bboxes from RPN  - epoch {}'.format(epoch_num + 1), y=1.1)\n",
    "                plt.ylabel('accuracy')\n",
    "                plt.xlabel('epoch length')\n",
    "                plt.ylim(0, 8)\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                fig_acc.savefig('results/acc_epoch_{}.pdf'.format(epoch_num + 1))\n",
    "            \n",
    "                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
    "                rpn_accuracy_for_epoch = []\n",
    "\n",
    "                if C.verbose:\n",
    "                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
    "                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
    "                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
    "                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
    "                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
    "                    print('Loss Detector regression: {}'.format(loss_class_regr))\n",
    "                    print('Elapsed time: {}'.format(time.time() - start_time))\n",
    "\n",
    "                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "                iter_num = 0\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Plot average total loss per epoch \n",
    "                plot_acc_loss['epoch_num'].append(epoch_num + 1)\n",
    "                plot_acc_loss['total_loss'].append(curr_loss)\n",
    "            \n",
    "                # update changes in loss\n",
    "                if curr_loss < best_loss:\n",
    "                    if C.verbose:\n",
    "                        print('Total loss decreased from {} to {}, saving weights'\n",
    "                               .format(best_loss,curr_loss))\n",
    "                               \n",
    "                    best_loss = curr_loss\n",
    "                    model_all.save_weights(C.model_path)\n",
    "                    \n",
    "                    # epoch chekpoint, not sure it works. \n",
    "                    model_all.save('checkpoints/model_epoch_{}.h5'\n",
    "                                    .format(epoch_num+1)) \n",
    "                break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('Exception: {}'.format(e))\n",
    "            continue\n",
    "\n",
    "print('Training complete, exiting.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results\n",
    "\n",
    "Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(num, x, y1, y2, title, ylabel, xlabel, leg1, leg2):\n",
    "    \n",
    "    if y2 is not None:      \n",
    "        fig = plt.figure(num)\n",
    "        plt.plot(plot_acc_loss[x], plot_acc_loss[y1], 'r', label=leg1)  \n",
    "        plt.plot(plot_acc_loss[x], plot_acc_loss[y2], 'b', label=leg2)\n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "                           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "        plt.title(title, y=1.10)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylim(0, 8)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    else:\n",
    "        fig = plt.figure(num)\n",
    "        plt.plot(plot_acc_loss[x], plot_acc_loss[y1], 'r', label=leg1)  \n",
    "        plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "                           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "        plt.title(title, y=1.10)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylim(0, 8)        \n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    return fig "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig1 = plot(1, 'epoch', 'rpn_acc', 'cls_acc', 'RPN - classifier accuracy',\n",
    "            'accuracy', 'epochs', 'overlapping bboxes', 'classifier accuracy')\n",
    "\n",
    "fig2 = plot(2, 'epoch', 'loss_rpn_cls', 'loss_rpn_regr', 'loss RPN', 'loss', \n",
    "               'epochs', 'loss RPN classifier', 'loss RPN regressor') \n",
    "\n",
    "fig3 = plot(3, 'epoch', 'loss_class_cls', 'loss_class_regr', 'loss detector', \n",
    "               'loss', 'epochs', 'loss detector classifier', 'loss detecor regression') \n",
    "\n",
    "fig4 = plot(4, 'epoch_num', 'total_loss', None, 'total loss', 'loss', 'epoch', \n",
    "             'total loss', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save plots and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save figures\n",
    "fig1.savefig('results/rpn_class_acc.pdf')\n",
    "fig2.savefig('results/loss_rpn_cls_regr.pdf')\n",
    "fig3.savefig('results/loss_det_cls_regr.pdf')\n",
    "fig4.savefig('results/total_loss.pdf')\n",
    "\n",
    "# plot models\n",
    "plot_model(model_rpn, to_file='nets/model_rpn.png')\n",
    "plot_model(model_classifier, to_file='nets/model_classifier.png')\n",
    "# plot_model(model_mask, to_file='nets/model_mask.png')\n",
    "plot_model(model_all, to_file='nets/model_all.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate mAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_map(pred, gt, f):\n",
    "    \n",
    "    T = {}\n",
    "    P = {}\n",
    "    fx, fy = f\n",
    "    \n",
    "    for bbox in gt: bbox['bbox_matched'] = False\n",
    "    \n",
    "    pred_probs = np.array(s['prob'] for s in pred)\n",
    "    box_idx_sorted_by_prob = np.argsort(pred_probs)[::-1]\n",
    "    \n",
    "    # if there are any predictions...\n",
    "    if pred:\n",
    "        \n",
    "        # get predicted and ground truth boxes to calculate IoU\n",
    "        for box_idx in box_idx_sorted_by_prob:            \n",
    "\n",
    "            pred_box = pred[box_idx]\n",
    "            pred_class = pred_box['class']\n",
    "            pred_x1 = pred_box['x1']\n",
    "            pred_x2 = pred_box['x2']\n",
    "            pred_y1 = pred_box['y1']\n",
    "            pred_y2 = pred_box['y2']\n",
    "            pred_prob = pred_box['prob']\n",
    "            \n",
    "            if pred_class not in P:\n",
    "                P[pred_class] = []\n",
    "                T[pred_class] = []\n",
    "\n",
    "            P[pred_class].append(pred_prob)\n",
    "            found_match = False\n",
    "            \n",
    "            for gt_box in gt:\n",
    "                \n",
    "                gt_class = gt_box['class']\n",
    "                gt_x1 = gt_box['x1']\n",
    "                gt_x2 = gt_box['x2']\n",
    "                gt_y1 = gt_box['y1']\n",
    "                gt_y2 = gt_box['y2']\n",
    "                gt_seen = gt_box['bbox_matched']\n",
    "                \n",
    "                if gt_class != pred_class: continue\n",
    "                if gt_seen: continue\n",
    "                \n",
    "                # calculate intersection ofver union for predicted bounding box\n",
    "                iou = data_generators.iou((pred_x1, pred_y1, pred_x2, pred_y2), \n",
    "                                          (gt_x1, gt_y1, gt_x2, gt_y2))\n",
    "                \n",
    "                # if the intersection is greater than the set threshold then it's a TP\n",
    "                if iou >= 0.5:\n",
    "                    found_match = True\n",
    "                    gt_box['bbox_matched'] = True\n",
    "                    break\n",
    "                else: continue\n",
    "                \n",
    "            T[pred_class].append(int(found_match))\n",
    "    \n",
    "    for gt_box in gt:\n",
    "\n",
    "        if not gt_box['bbox_matched']:\n",
    "            if gt_box['class'] not in P:\n",
    "                P[gt_box['class']] = []\n",
    "                T[gt_box['class']] = []                \n",
    "\n",
    "            P[gt_box['class']].append(1)\n",
    "            T[gt_box['class']].append(0)\n",
    "    \n",
    "    return T, P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open config.pickle from training \n",
    "with open(config_output_filename, 'r') as f_in:\n",
    "\tC = pickle.load(f_in)\n",
    "    \n",
    "# turn off any data augmenttaion at test time\n",
    "C.use_horizontal_flips = False\n",
    "C.use_vertical_flips = False\n",
    "C.rot_90 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formating image to be processed by Tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_img(img, C):\n",
    "    \n",
    "    # get the minimum size\n",
    "    img_min_side = float(C.im_size)\n",
    "    (h, w, _) = img.shape\n",
    "    \n",
    "    if w <= h:\n",
    "        f = img_min_side / w\n",
    "        nh = int(f * h)        # new height\n",
    "        nw = int(img_min_side) # new width \n",
    "    else:\n",
    "        f = img_min_side / h\n",
    "        nw = int(f * w)\n",
    "        nh = int(img_min_side)\n",
    "    \n",
    "    fx = w / float(nw)\n",
    "    fy = h / float(nh)\n",
    "    \n",
    "    # resize\n",
    "    img = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_CUBIC)\n",
    "    img = img[:, :, (2, 1, 0)]\n",
    "    img = img.astype(np.float32)\n",
    "    \n",
    "    # zero center\n",
    "    img[:, :, 0] -= C.img_channel_mean[0]\n",
    "    img[:, :, 1] -= C.img_channel_mean[1]\n",
    "    img[:, :, 2] -= C.img_channel_mean[2]    \n",
    "    \n",
    "    # transpose \n",
    "    img /= C.img_scaling_factor\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    return img, fx, fy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class mapping and image shaping\n",
    "class_mapping = {v: k for k, v in class_mapping.iteritems()}\n",
    "print(class_mapping)\n",
    "class_to_color = {class_mapping[v]: np.random.randint(0, 255, 3) for v in class_mapping}    \n",
    "C.num_rois = int(options.num_rois)\n",
    "\n",
    "# set network features depending on the network specified by the config.pickle\n",
    "if C.network == 'resnet50': num_features = 1024\n",
    "elif C.network == 'vgg': num_features = 512\n",
    "\n",
    "# dimension ordering using Tensorflow \n",
    "input_shape_img = (None, None, 3)\n",
    "input_shape_features = (None, None, num_features)\n",
    "\n",
    "# img_input = Input(shape=input_shape_img)\n",
    "# roi_input = Input(shape=(C.num_rois, 4))\n",
    "feature_map_input = Input(shape=input_shape_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define test models, load weights from config.pickle and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define rpn model \n",
    "rpn_l = nn.rpn(shared_layers, num_anchors)\n",
    "model_rpn_l = Model(img_input, rpn_l)\n",
    "\n",
    "# define class model \n",
    "class_l = nn.classifier(feature_map_input, roi_input, C.num_rois, \n",
    "                        nb_classes=len(class_mapping), trainable=True)\n",
    "\n",
    "model_classifier_lo = Model([feature_map_input, roi_input], class_l)\n",
    "model_classifier_l = Model([feature_map_input, roi_input], class_l)\n",
    "\n",
    "# load model weights generated during training \n",
    "model_rpn_l.load_weights(C.model_path, by_name=True)\n",
    "model_classifier_l.load_weights(C.model_path, by_name=True)\n",
    "\n",
    "# compile models \n",
    "model_rpn_l.compile(optimizer='sgd', loss='mse')\n",
    "model_classifier_l.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bbox_threshold = 0.0\n",
    "visualize = True\n",
    "T = {}\n",
    "P = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(val_imgs)):\n",
    "    \n",
    "    # get image data\n",
    "    print('{}/{}'.format(idx, len(val_imgs)))\n",
    "    st = time.time()    \n",
    "    X, Y, img_data = next(data_gen_val)\n",
    "    filepath = img_data['filepath']\n",
    "    img = cv2.imread(filepath)\n",
    "    X, fx, fy = format_img(img, C)\n",
    "    \n",
    "    # scale image\n",
    "    img_scaled = np.transpose(X.copy()[0, (2, 1, 0), :, :], (1, 2, 0)).copy()\n",
    "    img_scaled[:, :, 0] += 123.680\n",
    "    img_scaled[:, :, 1] += 116.779\n",
    "    img_scaled[:, :, 2] += 103.939\n",
    "    \n",
    "    img_scaled = img_scaled.astype(np.uint8)\n",
    "    \n",
    "    if K.image_dim_ordering() == 'tf': X = np.transpose(X, (0, 2, 3, 1))\n",
    "        \n",
    "    # get the feature maps and output from rpn \n",
    "    [Y1, Y2, F] = model_rpn_l.predict(X)\n",
    "    \n",
    "    # convert rpn to roi\n",
    "    R = roi_helpers.rpn_to_roi(Y1, Y2, C, K.image_dim_ordering(), overlap_thresh=0.7)\n",
    "    \n",
    "    # convert from (x1, y1, x2, y2) to (x, y, w, h)\n",
    "    R[:, 2] -= R[:, 0]\n",
    "    R[:, 3] -= R[:, 1]\n",
    "    \n",
    "    # apply the spp to the proposed regions \n",
    "    bboxes = {}\n",
    "    probs = {}\n",
    "    \n",
    "    for jk in range(R.shape[0] // C.num_rois + 1):\n",
    "        ROIs = np.expand_dims(R[C.num_rois * jk: C.num_rois * (jk +1), :], axis=0)\n",
    "        \n",
    "        if ROIs.shape[1] == 0: break\n",
    "        \n",
    "        if jk == R.shape[0] // C.num_rois:\n",
    "            \n",
    "            curr_shape = ROIs.shape\n",
    "            target_shape = (curr_shape[0], C.num_rois, curr_shape[2])\n",
    "            ROIs_padded = np.zeros(target_shape).astype(ROIs.dtype)\n",
    "            ROIs_padded[:, :curr_shape[1], :] = ROIs\n",
    "            ROIs_padded[0, curr_shape[1]:, :] = ROIs[0, 0, :]\n",
    "            ROIs = ROIs_padded\n",
    "        \n",
    "        [P_cls, P_regr] = model_classifier_lo.predict([F, ROIs])\n",
    "        \n",
    "        for ii in range(P_cls.shape[1]):\n",
    "            \n",
    "            if np.max(P_cls[0, ii, :]) < bbox_threshold or np.argmax(P_cls[0, ii, :]) == (P_cls.shape[2] - 1):\n",
    "                continue\n",
    "            \n",
    "            cls_name = class_mapping[np.argmax(P_cls[0, ii, :])]\n",
    "            \n",
    "            if cls_name not in bboxes:\n",
    "                bboxes[cls_name] = []\n",
    "                probs[cls_name] = []\n",
    "                \n",
    "            (x, y, w, h) = ROIs[0, ii, :]            \n",
    "            cls_num = np.argmax(P_cls[0, ii, :])\n",
    "            \n",
    "            try:\n",
    "                (tx, ty, tw, th) = P_regr[0, ii, 4 * cls_num:4 * (cls_num + 1)]\n",
    "                tx /= C.classifier_regr_std[0]\n",
    "                ty /= C.classifier_regr_std[1]\n",
    "                tw /= C.classifier_regr_std[2]\n",
    "                th /= C.classifier_regr_std[3]\n",
    "                x, y, w, h = roi_helpers.apply_regr(x, y, w, h, tx, ty, tw, th)\n",
    "            except: pass\n",
    "            \n",
    "            bboxes[cls_name].append([16 * x, 16 * y, 16 * (x + w), 16 * (y + h)])\n",
    "            probs[cls_name].append(np.max(P_cls[0, ii, :]))\n",
    "            \n",
    "        all_dets = []\n",
    "        \n",
    "        for key in bboxes:            \n",
    "            bbox = np.array(bboxes[key])\n",
    "            new_boxes, new_probs = roi_helpers.non_max_suppression_fast(bbox, np.array(probs[key]), overlap_thresh=0.5)\n",
    "            \n",
    "            for jk in range(new_boxes.shape[0]):                \n",
    "                \n",
    "                (x1, y1, x2, y2) = new_boxes[jk, :]                \n",
    "                \n",
    "                # bounding box \n",
    "                cv2.rectangle(img_scaled, \n",
    "                              (x1, y1), \n",
    "                              (x2, y2), \n",
    "                              class_to_color[key], 2)                    \n",
    "                \n",
    "                # text     \n",
    "                textLabel = '{}: {}'.format(key, float(\"{0:.4f}\".format(new_probs[jk])))\n",
    "                det = {'x1': x1, 'x2': x2, 'y1': y1, 'y2': y2, 'class': key, 'prob': new_probs[jk]}\n",
    "                all_dets.append(det)                \n",
    "                (retval, baseLine) = cv2.getTextSize(textLabel, cv2.FONT_HERSHEY_PLAIN, 1, 1)\n",
    "                textOrg = (x1, y1 + 20)                \n",
    "                \n",
    "                # rectangle label\n",
    "                cv2.rectangle(img_scaled, \n",
    "                             (textOrg[0] - 5, textOrg[1] + baseLine - 5),\n",
    "                             (textOrg[0] + retval[0] + 5, textOrg[1] - retval[1] - 5), \n",
    "                             (0, 0, 0), 2)                \n",
    "                \n",
    "                # rectangle label\n",
    "                cv2.rectangle(img_scaled, \n",
    "                             (textOrg[0] - 5, textOrg[1] + baseLine - 5),\n",
    "                             (textOrg[0] + retval[0] + 5, textOrg[1] - retval[1] - 5), \n",
    "                             class_to_color[key], -1)                              \n",
    "                \n",
    "                # add label class\n",
    "                cv2.putText(img_scaled, textLabel, textOrg, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "                \n",
    "        print('Elapsed time = {}'.format(time.time() - st))        \n",
    "        t, p = get_map(all_dets, img_data['bboxes'], (fx, fy))        \n",
    "\n",
    "        for key in t.keys():\n",
    "            if key not in T:\n",
    "                T[key] = []\n",
    "                P[key] = []\n",
    "            T[key].extend(t[key])\n",
    "            P[key].extend(p[key])\n",
    "        \n",
    "        all_aps = []\n",
    "        \n",
    "        for key in T.keys():\n",
    "            ap = average_precision_score(T[key], P[key])\n",
    "            print('{} AP: {}'.format(key, ap))\n",
    "            all_aps.append(ap)\n",
    "        \n",
    "        print('mAP = {}'.format(np.mean(np.array(all_aps))))        \n",
    "        plot_acc_loss['mAP'].append(np.mean(np.array(all_aps)))\n",
    "        \n",
    "    print(all_dets)\n",
    "    cv2.imshow('img', img_scaled)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imwrite('./results/detected_mAP{}.png'.format(idx), img_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lim = (max(plot_acc_loss['mAP']))\n",
    "fig_mAP = plt.figure(0)\n",
    "plt.plot(plot_acc_loss['mAP'], 'r', label='mAP')  \n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "                           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.title('mAP'.format(epoch_num + 1), y=1.1)\n",
    "plt.ylabel('mAP')\n",
    "plt.xlabel('iter')\n",
    "plt.ylim(0, 2)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close()\n",
    "fig_loss.savefig('results/mAP.pdf'.format(epoch_num + 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
